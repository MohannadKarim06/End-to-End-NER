{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ql6lvyIlrk2A",
        "outputId": "86319366-6dcb-43b4-dc35-bcfb976d0656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLgKinmWGXTw"
      },
      "outputs": [],
      "source": [
        "ds = load_dataset(\"Rosenberg/conll2003\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_It5_LuyHy-_"
      },
      "outputs": [],
      "source": [
        "ds = ds.remove_columns([\"tags\", \"rtokens\", \"pos\", \"ltokens\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6GaqLRAUIhB",
        "outputId": "88c3f0b1-4e4f-4b48-ff32-31fe4c7aacfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-2c65d79c1352>:9: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  data = ds[\"train\"].to_pandas().applymap(convert_to_serializable).to_dict(orient=\"records\") # Apply function to DataFrame\n",
            "<ipython-input-20-2c65d79c1352>:13: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  data = ds[\"test\"].to_pandas().applymap(convert_to_serializable).to_dict(orient=\"records\") # Apply function to DataFrame\n",
            "<ipython-input-20-2c65d79c1352>:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  data = ds[\"validation\"].to_pandas().applymap(convert_to_serializable).to_dict(orient=\"records\") # Apply function to DataFrame\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import numpy as np # Import numpy\n",
        "\n",
        "def convert_to_serializable(item): # Define function to handle NumPy arrays\n",
        "  if isinstance(item, np.ndarray):\n",
        "    return item.tolist()\n",
        "  return item\n",
        "\n",
        "data = ds[\"train\"].to_pandas().applymap(convert_to_serializable).to_dict(orient=\"records\") # Apply function to DataFrame\n",
        "with open(\"/content/drive/MyDrive/End to End NER project/NER_train_data.json\", \"w\") as f:\n",
        "  json.dump(data, f, indent=4)\n",
        "\n",
        "data = ds[\"test\"].to_pandas().applymap(convert_to_serializable).to_dict(orient=\"records\") # Apply function to DataFrame\n",
        "with open(\"/content/drive/MyDrive/End to End NER project/NER_test_data.json\", \"w\") as f:\n",
        "  json.dump(data, f, indent=4)\n",
        "\n",
        "data = ds[\"validation\"].to_pandas().applymap(convert_to_serializable).to_dict(orient=\"records\") # Apply function to DataFrame\n",
        "with open(\"/content/drive/MyDrive/End to End NER project/NER_validation_data.json\", \"w\") as f:\n",
        "  json.dump(data, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qcsfsd5tEDi"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/drive/MyDrive/End to End NER project/NER_train_data.json\", \"r\") as f:\n",
        "  train_data = json.load(f)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/End to End NER project/NER_validation_data.json\", \"r\") as f:\n",
        "  test_data = json.load(f)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/End to End NER project/NER_test_data.json\", \"r\") as f:\n",
        "  validation_data = json.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VV8HPJM4uUdC"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(data):\n",
        "\n",
        "  text = \" \".join(data[\"tokens\"])\n",
        "  position = 0\n",
        "  char_offsets = {}\n",
        "\n",
        "  for idx, word in enumerate(data[\"tokens\"]):\n",
        "    start = position\n",
        "    end = start + len(word)\n",
        "\n",
        "    char_offsets[idx] = (start, end)\n",
        "\n",
        "    position = end + 1\n",
        "\n",
        "  new_entities = []\n",
        "  for entity in data[\"entities\"]:\n",
        "    word_start = entity[\"start\"]\n",
        "    word_end = entity[\"end\"]\n",
        "\n",
        "    char_start = char_offsets[word_start][0]\n",
        "    char_end = char_offsets[word_end - 1][1]\n",
        "    new_entities.append({\"start\": char_start, \"end\": char_end, \"label\": entity[\"type\"].upper()})\n",
        "\n",
        "  return {\"text\": text, \"entity\": new_entities}\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_train_data = [preprocess_data(item) for item in train_data]\n",
        "processed_test_data = [preprocess_data(item) for item in test_data]\n",
        "processed_validation_data = [preprocess_data(item) for item in validation_data]"
      ],
      "metadata": {
        "id": "1UnYQXRW07gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRerNufb45yS"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/End to End NER project/NER_train_data.json', 'w') as outfile:\n",
        "        json.dump(processed_train_data, outfile, indent=4)\n",
        "\n",
        "with open('/content/drive/MyDrive/End to End NER project/NER_test_data.json', 'w') as outfile:\n",
        "        json.dump(processed_test_data, outfile, indent=4)\n",
        "\n",
        "with open('/content/drive/MyDrive/End to End NER project/NER_validation_data.json', 'w') as outfile:\n",
        "        json.dump(processed_validation_data, outfile, indent=4)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}